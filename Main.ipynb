{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTALACIÓN DE LAS LIBRERÍAS"
      ],
      "metadata": {
        "id": "U1IfQbW8r-uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/UNET5G"
      ],
      "metadata": {
        "id": "EUDLzK1sKSax"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvsfNaYbKVF5",
        "outputId": "961d292b-4cbe-4da7-9fa1-0d7a5ac4ddb1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IvanGarcia7/UNET5G.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMSTaOam3_4U",
        "outputId": "9355a87c-be70-4af9-8f68-9287d83b5bea"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UNET5G'...\n",
            "remote: Enumerating objects: 4828, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 4828 (delta 9), reused 83 (delta 7), pack-reused 4743\u001b[K\n",
            "Receiving objects: 100% (4828/4828), 206.91 MiB | 34.88 MiB/s, done.\n",
            "Resolving deltas: 100% (1614/1614), done.\n",
            "Updating files: 100% (13919/13919), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ktbcEHqV4t",
        "outputId": "ea744356-a1a8-4f8f-851e-3c9176d39d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UNET5G/Code/Pytorch-UNet\n"
          ]
        }
      ],
      "source": [
        "cd /content/UNET5G/Code/Pytorch-UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn1pPmPukP32",
        "outputId": "8c2d420e-c3f1-44bb-b9af-21fb80f904ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib==3.6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.6.2)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: Pillow==9.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (9.3.0)\n",
            "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.64.1)\n",
            "Requirement already satisfied: wandb==0.13.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.13.5)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (1.0.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (2.5.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.5->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=1.0.0->wandb==0.13.5->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5->-r requirements.txt (line 5)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5->-r requirements.txt (line 5)) (2024.6.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.5->-r requirements.txt (line 5)) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "iafmWwelxjya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "-gH8WS9hxsiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdaQtwgYKY6T"
      },
      "source": [
        "# PREPARACIÓN DE LOS DATOS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFqhfq3bKcNo"
      },
      "source": [
        "El modelo está diseñado para aceptar como entrada una matriz de tamaño fijo, por ejemplo 100 x 100 y con 8 dimensiones. Estas dimensiones estarían compuestas por:\n",
        "\n",
        "\n",
        "*   Path_Loss\n",
        "*   Respectivos SNR de cada estación base\n",
        "*   Despliegue de cada una de las estaciones base\n",
        "*   Despliegue de los usuarios\n",
        "\n",
        "\n",
        "Como salida, el modelo genera una matriz con el mismo tamaño que una de las dimensiones de la matriz de entrada. Esta matríz tendrá una sola dimensión y contendrá información acerca del ancho de banda estimado.\n",
        "\n",
        "A continuación, se especifíca el código necesario para generar una matriz de ejemplo, la cual se le dará como entrada al modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HQWwC453u6_",
        "outputId": "9dc7eda5-da20-4476-8f80-43640b0dae8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-0-4605876  0-0-4612497-0  0-0-4612497-1  0-0-4612497-2\n"
          ]
        }
      ],
      "source": [
        "!ls /content/UNET5G/SAMPLE/adaptive_0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de los datos en forma de matriz dado un directorio"
      ],
      "metadata": {
        "id": "I6PaAO0CuTIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/Matrices"
      ],
      "metadata": {
        "id": "AHEA5gEHKmhP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/Matrices\n",
        "!mkdir /content/Matrices/IN\n",
        "!mkdir /content/Matrices/OUT\n",
        "!mkdir /content/Matrices/TEST/\n",
        "!mkdir /content/Matrices/TEST/IN\n",
        "!mkdir /content/Matrices/TEST/OUT"
      ],
      "metadata": {
        "id": "A__17N2uKfn8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "_eqJR6QVqV4w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from natsort import natsorted\n",
        "\n",
        "#Ruta donde se encuentran los archivos, por ejemplo '/opt/share/MERIDA/Data/adaptive_0/0-0-4605876/ia/raw/'\n",
        "folder = '/content/UNET5G/SAMPLE/adaptive_0/0-0-4605876/ia/raw/'\n",
        "\n",
        "#Ruta donde se van a almacenar las matrices ya procesadas, por ejemplo '/opt/share/MERIDA/DATASET-TEST/'\n",
        "folder_output = '/content/Matrices/'\n",
        "\n",
        "#Indicar si se va a realizar o no estandarización de los datos\n",
        "estandarizacion = False\n",
        "\n",
        "lista = os.listdir(folder+'deployment/')\n",
        "lista = natsorted(lista)\n",
        "\n",
        "for i in range(0,len(lista)-3):\n",
        "    deploy_femto = folder+'deployment/'+str(i)+'_femto'\n",
        "    deploy_micro = folder+'deployment/'+str(i)+'_micro'\n",
        "    deploy_pico = folder+'deployment/'+str(i)+'_pico'\n",
        "    if os.path.isfile(deploy_femto) and os.path.isfile(deploy_micro) and os.path.isfile(deploy_pico):\n",
        "        snr_femto = folder+'snr/'+str(i)+'_femto'\n",
        "        snr_micro = folder+'snr/'+str(i)+'_micro'\n",
        "        snr_pico = folder+'snr/'+str(i)+'_pico'\n",
        "        if os.path.isfile(snr_femto) and os.path.isfile(snr_micro) and os.path.isfile(snr_pico):\n",
        "            user_data = folder+'users'\n",
        "            pathloss_data = folder+'pathloss'\n",
        "\n",
        "            matriz_femto_snr = np.loadtxt(snr_femto, dtype=float)\n",
        "            matriz_micro_snr = np.loadtxt(snr_micro, dtype=float)\n",
        "            matriz_pico_snr = np.loadtxt(snr_pico, dtype=float)\n",
        "            matriz_femto_deploy = np.loadtxt(deploy_femto, dtype=float)\n",
        "            matriz_micro_deploy = np.loadtxt(deploy_micro, dtype=float)\n",
        "            matriz_pico_deploy = np.loadtxt(deploy_pico, dtype=float)\n",
        "            matriz_pathloss = np.loadtxt(pathloss_data, dtype=float)\n",
        "            matriz_users = np.loadtxt(user_data, dtype=float)\n",
        "\n",
        "            # Combina las matrices en una sola matriz de 8 dimensiones\n",
        "            matriz_combinada = np.array([matriz_femto_snr, matriz_micro_snr, matriz_pico_snr,\n",
        "                                         matriz_femto_deploy, matriz_micro_deploy, matriz_pico_deploy,\n",
        "                                         matriz_pathloss, matriz_users])\n",
        "\n",
        "            if estandarizacion:\n",
        "              # Índices de las matrices que deseas estandarizar\n",
        "              indices_estandarizar = [0, 1, 2, 6]\n",
        "\n",
        "              # Calcula la media y la desviación estándar para las matrices seleccionadas\n",
        "              medias = np.mean(matriz_combinada[indices_estandarizar], axis=(0, 1))\n",
        "              desviaciones_estandar = np.std(matriz_combinada[indices_estandarizar], axis=(0, 1))\n",
        "\n",
        "              # Estandariza las matrices seleccionadas\n",
        "              for i in indices_estandarizar:\n",
        "                  if desviaciones_estandar[i] != 0:\n",
        "                      matriz_combinada[i] = (matriz_combinada[i] - medias) / desviaciones_estandar\n",
        "\n",
        "            ruta_guardado_binario = folder_output+'IN/matriz_combinada'+str(i)+'.npy'\n",
        "            np.save(ruta_guardado_binario, matriz_combinada)\n",
        "\n",
        "            # Leer los datos desde el archivo CSV para generar los ficheros de salida con el que comparar las soluciones\n",
        "            data = np.genfromtxt(folder+'usersInfo/'+str(i)+'.csv', delimiter=',', skip_header=1)\n",
        "\n",
        "            # Obtener las coordenadas x, y y capacidad\n",
        "            x = data[:, 1].astype(int)\n",
        "            y = data[:, 2].astype(int)\n",
        "            capacity = data[:, 4]\n",
        "\n",
        "            # Obtener las dimensiones de la matriz\n",
        "            max_x, max_y = np.max(x), np.max(y)\n",
        "\n",
        "            # Crear una matriz de ceros con las dimensiones máximas\n",
        "            matrix = np.zeros((100, 100))\n",
        "\n",
        "            # Asignar los valores de capacidad en las posiciones correspondientes\n",
        "            matrix[x, y] = capacity\n",
        "\n",
        "            # Guardar la matriz en formato binario de NumPy (npy)\n",
        "            ruta_guardado_binario = folder_output+'OUT/matriz_combinada'+str(i)+'.npy'\n",
        "            np.save(ruta_guardado_binario, matrix)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se destina un conjunto de datos a TEST"
      ],
      "metadata": {
        "id": "Mla0B5lRw0Hl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4clcgt2HqV40",
        "outputId": "a356e061-e118-44b7-dce3-cff47f1c9959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matriz_combinada0.npy matriz_combinada218.npy\n",
            "46\n",
            "matriz_combinada208.npy matriz_combinada11.npy\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Ruta del cual extraer las muestras para TEST'\n",
        "folder_output = '/content/Matrices/'\n",
        "lista_ficheros = os.listdir(folder_output+'IN/')\n",
        "ruta_destino = folder_output+'TEST/IN'\n",
        "\n",
        "random.shuffle(lista_ficheros)\n",
        "random.shuffle(lista_ficheros)\n",
        "\n",
        "num_archivos_validacion = int(len(lista_ficheros)*0.10)\n",
        "archivos_validacion_completo = random.sample(lista_ficheros, num_archivos_validacion)\n",
        "\n",
        "print(lista_ficheros[1],lista_ficheros[2])\n",
        "print(len(archivos_validacion_completo))\n",
        "print(archivos_validacion_completo[1],archivos_validacion_completo[2])\n",
        "\n",
        "for archivo in archivos_validacion_completo:\n",
        "    origenin = folder_output+'IN/'+archivo\n",
        "    destinoin = folder_output+'TEST/IN/'+archivo\n",
        "    shutil.move(origenin, destinoin)\n",
        "\n",
        "    origenout = folder_output+'OUT/'+archivo\n",
        "    destinoout = folder_output+'TEST/OUT/'+archivo\n",
        "    shutil.move(origenout, destinoout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAFMMakcRW8r"
      },
      "source": [
        "# ENTRENAMIENTO DEL MODELO\n",
        "\n",
        "### V6 versión modificada para permitir utilizar múltiples GPU's + Early Stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dentro de train_v6.py, modificar las siguientes rutas:\n",
        "\n",
        "* dir_img = Path('/opt/share/MERIDA/DATASET-TESTALL2/IN/')\n",
        "* dir_mask = Path('/opt/share/MERIDA/DATASET-TESTALL2/OUT/')\n",
        "* dir_checkpoint = Path('/opt/share/MERIDA/Code/Pytorch-UNet/checkpoints2/')\n",
        "* early_stopping = EarlyStopping(patience=50, checkpoint_path='/opt/shareMERIDA/\n",
        "Code/Pytorch-UNet/checkpoints/early_stop_checkpoint.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "3snbhe095UKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20moIrwgv-FU"
      },
      "outputs": [],
      "source": [
        "!python train_v6.py --amp --epochs 500"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se copia el modelo ya entranado a la ruta requerida"
      ],
      "metadata": {
        "id": "K_Sm98Viz2Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos subidos a https://mega.nz/folder/nBAVzJqZ#9_ODIDPU3kYwvX6t0r8Y_w"
      ],
      "metadata": {
        "id": "_4Xj2FkGJKcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/MERIDAV2/checkpoint_NORMAL.pth /content/UNET5G/Code/Pytorch-UNet/MODEL.pth"
      ],
      "metadata": {
        "id": "PMi-k-Bpz0wa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MEDIDAS EN BASE A LA ESTIMACIÓN REALIZADA"
      ],
      "metadata": {
        "id": "AvdDEndSzhDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek7LjSMmv-Ci"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ruta al archivo .npy de salida, por ejemplo '/opt/share/MERIDA/out/matriz_combinada15.npy'\n",
        "archivo_npy = '/content/Matrices/TEST/OUT/matriz_combinada1.npy'\n",
        "\n",
        "matriz = np.load(archivo_npy)\n",
        "\n",
        "# Obtener los índices de los elementos no cero\n",
        "indices_no_cero = np.nonzero(matriz)\n",
        "\n",
        "# Imprimir los valores no cero y sus índices\n",
        "for i, j in zip(indices_no_cero[0], indices_no_cero[1]):\n",
        "    valor = matriz[i, j]\n",
        "    print(f\"Valor no cero en la posición ({i}, {j}): {valor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESTIMACIÓN DE LA MATRIZ DE SALIDA EN BASE AL MODELO ENTRENADO\n",
        "\n",
        "-i 'Matriz de dimensionalidad 8 destinada para TEST'\n",
        "-o 'Matriz de dimensionalidad 1 con la estimación dada por el modelo'"
      ],
      "metadata": {
        "id": "hyD9u5MT0BSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/UNET5G/Code/Pytorch-UNet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnXHdtufJPRv",
        "outputId": "39000ff1-e86d-47fc-f20e-9e827f76a681"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UNET5G/Code/Pytorch-UNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plnQOU963jh_",
        "outputId": "418c8b75-36b2-406e-dfaf-c68439f5514d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Loading model MODEL.pth\n",
            "INFO: Using device cuda\n",
            "INFO: Model loaded!\n",
            "INFO: Predicting values for matrix /content/Matrices/TEST/IN/matriz_combinada1.npy ...\n",
            "(8, 100, 100)\n",
            "INFO: Regression values saved to /content/salidaexample1.npy\n"
          ]
        }
      ],
      "source": [
        "!python predictv3.py -i '/content/Matrices/TEST/IN/matriz_combinada1.npy' -o '/content/salidaexample1.npy'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DIFERENCIA ENTRE LOS VALORES REALES Y LOS ESTIMADOS"
      ],
      "metadata": {
        "id": "lD3oz0qk0XWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp3bWvMzqV45"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Cargar la matriz desde el archivo .npy con el GT, por ejemplo '/opt/share/MERIDA/DATASET-TESTALL/TEST/OUT/matriz_combinada43.npy'\n",
        "matriz = np.load('/content/Matrices/TEST/OUT/matriz_combinada1.npy')\n",
        "\n",
        "# Cargar la matriz desde el archivo .npy con las estimaciones, por ejemplo '/opt/share/MERIDA/SALIDA/salidabatch44.npy'\n",
        "matriz_pred = np.load('/content/salidaexample1.npy')\n",
        "\n",
        "# Obtener las posiciones donde los elementos no son cero\n",
        "posiciones_no_cero = np.nonzero(matriz)\n",
        "posiciones_cero = np.where(matriz==0)\n",
        "\n",
        "valores_reales = []\n",
        "valores_estimados = []\n",
        "\n",
        "print('POSICIONES DISTINTAS DE CERO')\n",
        "# Imprimir las posiciones y los valores correspondientes\n",
        "for fila, columna in zip(*posiciones_no_cero):\n",
        "    valor = matriz[fila, columna]\n",
        "    valorpred = matriz_pred[0][0][fila,columna]\n",
        "    print(f\"Posición ({fila}, {columna}): Valor GT = {valor}, Valor PRED = {valorpred}\")\n",
        "    valores_reales.append(valor)\n",
        "    valores_estimados.append(valorpred)\n",
        "\n",
        "#print('POSICIONES DE CERO')\n",
        "# Imprimir las posiciones y los valores correspondientes\n",
        "#for fila, columna in zip(*posiciones_cero):\n",
        "#    valor = matriz[fila, columna]\n",
        "#    valorpred = matriz_pred[0][0][fila,columna]\n",
        "#    print(f\"Posición ({fila}, {columna}): Valor GT = {valor}, Valor PRED = {valorpred}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CÁLCULO DE MEDIDAS"
      ],
      "metadata": {
        "id": "1sILsGwA0tIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpyLEcePqV45",
        "outputId": "8428bff0-d96f-4f95-a218-f4fbc2b1d01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error cuadrático medio (ECM): 22.948255799960382\n",
            "Error absoluto medio (EAM): 3.411395076761852\n",
            "Coeficiente de determinación (R-cuadrado): 0.9668148631708507\n",
            "Error medio de la raíz cuadrada (EMRC): 4.790433779936884\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Convertir las listas a arrays de numpy\n",
        "valores_reales = np.array(valores_reales)\n",
        "valores_estimados = np.array(valores_estimados)\n",
        "\n",
        "# Calcular las métricas\n",
        "ecm = mean_squared_error(valores_reales, valores_estimados)\n",
        "eam = mean_absolute_error(valores_reales, valores_estimados)\n",
        "r_cuadrado = r2_score(valores_reales, valores_estimados)\n",
        "emrc = np.sqrt(ecm)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Error cuadrático medio (ECM):\", ecm)\n",
        "print(\"Error absoluto medio (EAM):\", eam)\n",
        "print(\"Coeficiente de determinación (R-cuadrado):\", r_cuadrado)\n",
        "print(\"Error medio de la raíz cuadrada (EMRC):\", emrc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}